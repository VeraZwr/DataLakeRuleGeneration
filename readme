Full technical report version of our paper can be found https://www.overleaf.com/read/gdfryrbwwgwx#ab7fe9.

1. read file and generate data profile
    column_features: extract features
    reds.py: read the file and save the profile in results folder as .dictionary
2. rule generation
    generate_rules_from_profile.py
3. cross-table rule matching and sharing
    semantic similarity
    cluster the columns by profile (distribution characteristic similarity of columns (mean, proportion of unique values, rate of null values..)
4. error detection pipeline
    rule matching
    error scoring
    error clustering
which scenario i can share the rules ->trees
run matelda

######reds#####
Content Features
Structure Features
Dirtiness Features

##### System Architecture #####
main.py
config.py
rules/
    __init__.py
    base_rule.py
    dictionary_rule.py
    custom_rules.py
    loader.py
    evaluation.py # applying rules, evaluating clusters, and get error detect results
profiling/
    __init__.py
    profiler.py
util/
    __init__.py
    file_io.py
    feature_utils.py
    rule_utils.py
    clustering.py
    viz.py
    result_file_reader.py

    1. run profiler.py to generate profile for each data sets

